--- 
    name: GrailQA - Zero-shot Generalization
    datasetUrl: https://dki-lab.github.io/GrailQA/
---

|          Model / System           | Year |   EM   |   F1   |                           Reported by                           |
| :-------------------------------: | :--: | :----: | :----: | :-------------------------------------------------------------: |
|       TIARA + GAIN (T5-3B)        | 2023 |  71.8  |  77.8  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
|        Pangu (T5-3B)              | 2023 |  71.6  |  78.5  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
|        Pangu (T5-Large)           | 2023 |  71.0  |  78.4  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
|      TIARA + GAIN (T5-base)       | 2023 |  69.9  |  76.4  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
|        Pangu (BERT-base)          | 2023 |  69.1  |  76.1  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
|               TIARA               | 2022 |  68.0  |  73.9  | [Shu et al.](https://aclanthology.org/2022.emnlp-main.555.pdf)  |
|          DeCC(Anonymous)          | 2022 |   -    |  72.5  |       [Yu et al.](https://arxiv.org/pdf/2210.00063.pdf)         |
|       DECAF (BM25 + FiD-3B)       | 2022 |   -    |  72.3  |       [Yu et al.](https://arxiv.org/pdf/2210.00063.pdf)         |
|       UniParser (Anonymous)       | 2022 |   -    |  69.8  |       [Yu et al.](https://arxiv.org/pdf/2210.00063.pdf)         |
|      RnG-KBQA (single model)      | 2021 | 62.988 | 69.182 |       [Ye et al.](https://arxiv.org/pdf/2109.08678.pdf)         |
|     GPT-3.5-turbo (5-shot)        | 2023 |  61.9  |  67.2  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)        |
|     DECAF (BM25 + FiD-large)      | 2022 |   -    |  68.0  |       [Yu et al.](https://arxiv.org/pdf/2210.00063.pdf)         |
|             ArcaneQA              | 2022 |  52.9  |  66.0  | [Shu et al.](https://aclanthology.org/2022.emnlp-main.555.pdf)  |
|        S2QL (single model)        | 2021 | 55.122 | 63.598 |                            Anonymous                            |
|      ArcaneQA (single model)      | 2021 | 49.964 | 58.844 |                            Anonymous                            |
|    BERT+Ranking (single model)    | 2021 | 48.566 | 55.660 |         [Gu et al.](https://arxiv.org/abs/2011.07743)           |
|      ReTraCk (single model)       | 2021 | 44.561 | 52.539 |   [Chen et al.](https://aclanthology.org/2021.acl-demo.39/)     |
|                QGG                | 2022 |   -    |  36.6  |       [Yu et al.](https://arxiv.org/pdf/2210.00063.pdf)         |
|   GloVe+Ranking (single model)    | 2021 | 28.886 | 33.792 |         [Gu et al.](https://arxiv.org/abs/2011.07743)           |
| BERT+Transduction (single model)  | 2021 | 25.702 | 29.300 |         [Gu et al.](https://arxiv.org/abs/2011.07743)           |
| GloVe+Transduction (single model) | 2021 | 2.968  | 3.123  |         [Gu et al.](https://arxiv.org/abs/2011.07743)           |
