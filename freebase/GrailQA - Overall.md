---
    name: GrailQA - Overall
    datasetUrl: https://dki-lab.github.io/GrailQA/
---

|          Model / System           | Year |   EM   |   F1   |                           Reported by                           |
| :-------------------------------: | :--: | :----: | :----: | :-------------------------------------------------------------: |
|        TIARA + GAIN (T5-3B)       | 2023 |  76.3  |  81.5  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)       |
|            Pangu (T5-3B)          | 2023 |  75.4  |  81.7  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)       |
|       TIARA + GAIN (T5-base)      | 2023 |  75.1  |  80.6  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)       |
|          Pangu (T5-large)         | 2023 |  74.8  |  81.4  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)       |
|          Pangu (BERT-base)        | 2023 |  73.7  |  79.9  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)       |
|       DECAF (BM25 + FiD-3B)       | 2022 |   -    |  78.7  |       [Yu et al.](https://arxiv.org/pdf/2210.00063.pdf)        |
|               TIARA               | 2022 |  73.0  |  78.5  | [Shu et al.](https://aclanthology.org/2022.emnlp-main.555.pdf) |
|               DeCC                | 2022 |   -    |  77.6  |       [Yu et al.](https://arxiv.org/pdf/2210.00063.pdf)        |
|     DECAF (BM25 + FiD-large)      | 2022 |   -    |  76.0  |       [Yu et al.](https://arxiv.org/pdf/2210.00063.pdf)        |
|             UniParser             | 2022 |   -    |  74.6  |       [Yu et al.](https://arxiv.org/pdf/2210.00063.pdf)        |
|      RnG-KBQA (single model)      | 2021 | 68.778 | 74.422 |       [Ye et al.](https://arxiv.org/pdf/2109.08678.pdf)        |
|             ArcaneQA              | 2022 |  63.8  |  73.7  | [Shu et al.](https://aclanthology.org/2022.emnlp-main.555.pdf) |
|        S2QL (single model)        | 2021 | 57.456 | 66.186 |                            Anonymous                            |
|      ReTraCk (single model)       | 2021 | 58.136 | 65.285 |   [Chen et al.](https://aclanthology.org/2021.acl-demo.39/)    |
|            Pangu (Codex)          | 2023 |  56.4  |  65.0  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)       |
|           B-BINDER (6)-R          | 2023 |  53.2  |  58.5  |       [Shu et al.](https://arxiv.org/pdf/2309.08345.pdf)       |
|           BERT+Ranking            | 2022 |  50.6  |  58.0  | [Shu et al.](https://aclanthology.org/2022.emnlp-main.555.pdf) |
|      ArcaneQA (single model)      | 2021 | 57.872 | 64.924 |                            Anonymous                            |
|    BERT+Ranking (single model)    | 2021 | 50.578 | 57.988 |         [Gu et al.](https://arxiv.org/abs/2011.07743)          |
|              ChatGPT              | 2023 | 46.77  |   -    |       [Tan et al.](https://arxiv.org/pdf/2303.07992.pdf)       |
|   GloVe+Ranking (single model)    | 2021 | 39.521 | 45.136 |         [Gu et al.](https://arxiv.org/abs/2011.07743)          |
|                QGG                | 2022 |   -    |  36.7  |       [Yu et al.](https://arxiv.org/pdf/2210.00063.pdf)        |
|             GPT-3.5v3             | 2023 | 35.43  |   -    |       [Tan et al.](https://arxiv.org/pdf/2303.07992.pdf)       |
| BERT+Transduction (single model)  | 2021 | 33.255 | 36.803 |         [Gu et al.](https://arxiv.org/abs/2011.07743)          |
|             GPT-3.5v2             | 2023 | 30.50  |   -    |       [Tan et al.](https://arxiv.org/pdf/2303.07992.pdf)       |
|              FLAN-T5              | 2023 | 29.02  |   -    |       [Tan et al.](https://arxiv.org/pdf/2303.07992.pdf)       |
|               GPT-3               | 2023 | 27.58  |   -    |       [Tan et al.](https://arxiv.org/pdf/2303.07992.pdf)       |
| GloVe+Transduction (single model) | 2021 | 17.587 | 18.432 |         [Gu et al.](https://arxiv.org/abs/2011.07743)          |
